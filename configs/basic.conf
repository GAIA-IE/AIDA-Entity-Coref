basic {
  no_cuda = true
  max_span_width = 50

  # Learning-Related Configs
  epochs = 100
  transformer_learning_rate = 5e-05
  task_learning_rate = 0.0001
  dropout_rate = 0.25
  batch_size = 32
  max_grad_norm = 1.0

  # Architecture-Related Configs
  feature_size = 20
  ffnn_size = 500
  ffnn_depth = 2

  # Other Configs
  report_frequency = 1000
  gradient_checkpointing = true
}

spanbert_large = ${basic} {
  transformer = SpanBERT/spanbert-large-cased
}

roberta_large = ${basic} {
  transformer = roberta-large
}
